# Step 12: Sort & Aggregation

> ORDER BY with in-memory sort, GROUP BY, aggregate functions (COUNT, SUM, AVG, MIN, MAX).

# This Step I Learned

## Aggregate Expression Lifecycle: Transient Nodes and Planner Rewriting

The central challenge of aggregation is that aggregate function calls like `COUNT(*)` or `SUM(salary)` appear as ordinary expressions in the SQL syntax (mixed with column references, arithmetic, aliases), but they have fundamentally different evaluation semantics: they consume an entire group of rows rather than a single row. This mismatch between syntax and semantics requires a multi-phase transformation in the planner.

### The BoundExpr::AggregateCall Transient Variant

When `Expr::bind()` encounters a function call like `SUM(salary)`, it resolves the function name to an `AggregateFunction` enum value and produces a `BoundExpr::AggregateCall` node. This variant is **transient** — it exists only between expression binding and planner rewriting. It must never survive to evaluation time, because the Volcano iterator model evaluates expressions row-by-row, and aggregates require consuming all rows in a group before producing a result.

The planner's `rewrite_for_aggregate_output` performs the critical transformation: it walks each bound expression tree, extracts every `AggregateCall` node into a shared `Vec<AggregateOp>` (deduplicating via `PartialEq`), and replaces each call site with a `BoundExpr::Column` reference pointing to the Aggregate node's output position. After rewriting, the expression tree contains only column references and constants — safe for per-row evaluation on top of the Aggregate node's output.

```text
Before rewrite (bound against scan schema):
  BinaryOp(AggregateCall(SUM, [$col1 (salary)]), Add, Integer(1000))

After rewrite (bound against Aggregate output):
  BinaryOp(Column { index: 1 }, Add, Integer(1000))
  // index 0 = group key (dept), index 1 = SUM(salary) result
```

This approach consolidates all aggregate extraction into a single rewrite pass rather than scattering aggregate detection across the planner. The `PartialEq` derive on `BoundExpr` (a prerequisite for this step) enables structural comparison: when `SELECT SUM(salary), SUM(salary) + 1000` references the same aggregate twice, the second occurrence reuses the first's output position rather than creating a duplicate accumulator.

### Aggregate Context Detection

Determining whether a query requires aggregation is not limited to checking for GROUP BY. Any aggregate function call in SELECT, HAVING, or ORDER BY triggers aggregation context. This matters for queries like `SELECT x FROM t ORDER BY COUNT(*)` — the ORDER BY aggregate implies that `x` must appear in GROUP BY, and the planner must produce a `NonAggregatedColumn` error if it does not. The detection scans all three clause locations before deciding the planner path.

## Accumulator Trait: Stateful Per-Group Computation

Each aggregate function is implemented as an `Accumulator` trait object with a three-phase lifecycle: creation, feeding, and finishing. The trait is deliberately simple:

```rust
pub trait Accumulator: Send {
    fn feed(&mut self, value: &Value) -> Result<(), ExecutorError>;
    fn finish(&self) -> Value;
}
```

Two design decisions are worth noting:

**NULL skipping is the caller's responsibility**, not the accumulator's. The Aggregate executor node skips NULL values before calling `feed()` for all non-COUNT(\*) aggregates. COUNT(\*) is special: it feeds `Value::Null` once per row (the value is ignored; only the call count matters). This separation keeps accumulators simple — they never need to distinguish between "no values yet" and "all values were NULL."

**DISTINCT filtering is also external.** The Aggregate executor maintains a `HashSet<GroupKey>` per DISTINCT aggregate per group. Before feeding a value, the executor checks whether the value has been seen; duplicates are silently skipped. This keeps the accumulator interface uniform regardless of the DISTINCT flag.

### Type Promotion in SUM

SUM uses type promotion: integer inputs (Smallint, Integer, Bigint) are widened to Bigint via `Value::to_wide_numeric()`, and floating-point inputs (Real, Double) are widened to Double. Mixed integer-then-float feeds promote the running sum from Bigint to Double. SUM also uses checked arithmetic for integers, returning `IntegerOverflow` when the sum exceeds `i64::MAX`. AVG always returns Double, regardless of input type.

## GroupKey: Custom Equality for SQL Grouping Semantics

`Value` in enhance implements neither `Eq` nor `Hash`, for good reason: SQL NULL is not equal to anything (including itself), and floating-point NaN has similar comparison issues. However, GROUP BY requires that NULLs be grouped together and NaN values be grouped together — a different equality semantics than SQL comparison.

`GroupKey` wraps a `Vec<Value>` with custom `PartialEq`, `Eq`, and `Hash` implementations that satisfy GROUP BY semantics:

- NULL = NULL (all NULLs in a group key position are treated as one group)
- NaN = NaN (via `partial_cmp` which uses `total_cmp`-like ordering for floats)
- Hash uses discriminant tags plus value bits (floats use `to_bits()` for NaN-consistent hashing)

The same `GroupKey` type is reused for DISTINCT aggregate deduplication: each DISTINCT aggregate wraps its argument value in a single-element `GroupKey` for `HashSet` membership testing.

## Sort: Materializing Operator with Stable Ordering

The Sort executor is a materializing (blocking) operator: on the first `next()` call, it consumes all input rows, sorts them, and then emits one row at a time from the sorted buffer. This breaks the Volcano model's lazy streaming property, but sorting inherently requires seeing all data before producing output.

The sort comparator handles three concerns:

1. **NULL ordering**: Default behavior matches PostgreSQL — NULLS LAST for ASC, NULLS FIRST for DESC. Explicit `NULLS FIRST` / `NULLS LAST` overrides the default.
2. **Multi-key sorting**: Sort keys are evaluated in order; secondary keys break ties from primary keys.
3. **Stability**: Rust's `Vec::sort_by` is a stable sort, so rows with equal sort keys preserve their input order.

Sort key expressions are evaluated during comparison via `BoundExpr::evaluate()`. If evaluation fails (which should not happen in practice since types are validated at planning time), the result is treated as NULL and sorted to the end.

## ORDER BY Resolution: Three Cases in the Planner

ORDER BY expression resolution is more complex than it might appear, because ORDER BY can reference the result set in three different ways:

**Case A: Positional reference** — `ORDER BY 1` refers to the first SELECT list item (1-indexed). The planner uses the already-rewritten SELECT expression directly.

**Case B: Alias reference** — `ORDER BY total` where `total` is a SELECT alias. The planner matches the name against SELECT output descriptors (case-insensitive) and uses the corresponding rewritten expression.

**Case C: Arbitrary expression** — `ORDER BY salary * 2` or `ORDER BY COUNT(*)`. The expression is bound against the scan schema (pre-Projection, pre-Aggregate). If in aggregation context, it is further rewritten via `rewrite_for_aggregate_output`, which may add new aggregates to the shared list.

The `resolve_order_by_expr` helper encapsulates these three cases, and the same function is used for both aggregation and non-aggregation paths (with different `fallback_bind` closures).

## LIMIT/OFFSET: Planning-Time Evaluation

LIMIT and OFFSET values are evaluated at planning time, not execution time. The planner binds the expression with an empty column list (no column references allowed), evaluates it immediately, validates the result (must be integer, must be non-negative), and converts to `u64`. This means the Limit executor node receives pre-validated constants and needs no type checking or error handling — it simply counts rows.

A minor optimization: when both `limit` is `None` and `offset` is 0, the planner skips creating a Limit node entirely, avoiding a no-op wrapper in the plan tree.

## Plan Tree Shape

The final plan tree for a fully-featured aggregation query follows this structure:

```text
SeqScan → Filter (WHERE) → Aggregate → Filter (HAVING) → Sort → Projection → Limit
```

The Projection node sits between Sort and Limit (not before Sort) because ORDER BY expressions may reference columns that are not in the SELECT list. The Sort node operates on the Aggregate output schema (group keys + aggregate results), and the Projection then narrows the columns to the SELECT list. Limit wraps the outermost position so it can cap the final output.

For non-aggregation queries, the tree is simpler:

```text
SeqScan → Filter (WHERE) → Sort → Projection → Limit
```

## Shared Aggregate List Across Clauses

SELECT, HAVING, and ORDER BY all share a single `Vec<AggregateOp>` during rewriting. When HAVING references `COUNT(*) > 5` and SELECT also contains `COUNT(*)`, the HAVING rewrite finds the existing `COUNT(*)` entry via `PartialEq` on `AggregateOp` and reuses its output position. This ensures the Aggregate executor computes each unique aggregate exactly once, even when referenced from multiple clauses.

# Looking Forward

## External Sort (Production)

The Sort executor loads the entire result set into memory. For tables larger than available memory, production systems use external sort (disk-based merge sort) that spills intermediate runs to temporary files and merges them back.

## Sort-Based Grouping (Production)

The Aggregate executor uses a hash-based approach (`HashMap<GroupKey, Vec<Accumulator>>`), which loads all group keys and accumulators into memory simultaneously. For high-cardinality GROUP BY with many distinct groups, production systems use sort-based grouping with spill-to-disk: sort by group key, then aggregate consecutive runs of equal keys in a streaming fashion.

## DISTINCT Queries

`SELECT DISTINCT` is not yet supported. It could be implemented as a special case of GROUP BY (group by all SELECT columns with no aggregates), or as a post-Projection deduplication node.

## Scalar Functions

`Expr::bind()` currently rejects all non-aggregate function names with `Unsupported`. When scalar functions are added (e.g., `UPPER()`, `COALESCE()`), the `contains_aggregate` helper must be updated to recurse into function arguments, since a scalar function could contain an aggregate as an argument (e.g., `UPPER(MIN(name))`).

## HAVING Without GROUP BY

enhance currently rejects `HAVING` without GROUP BY or aggregates as `Unsupported`. PostgreSQL accepts this as treating the entire table as a single group, which would be a straightforward extension: add an empty `group_by` list and produce a scalar aggregate with the HAVING filter.

## Per-Row Future Allocation

As noted in Step 10, each `QueryNode::next()` call heap-allocates a `Box<dyn Future>`. Sort and Aggregate mitigate this somewhat by buffering all output rows internally, but the per-row cost still applies when emitting from the buffer. Enum-based future dispatch or batched row processing would reduce this overhead.
