# Step 10: Basic Executor & EXPLAIN

> Implement Volcano trait (`next() -> Option<Tuple>`), SeqScan (heap iteration with visibility check), Filter (WHERE evaluation), Projection (column selection), and EXPLAIN output for plan visualization.

# This Step I Learned

## The Volcano Model in Async Rust

The Volcano (iterator) model is the standard execution strategy in relational databases: each node in a query plan tree exposes a `next()` method, pulling one tuple at a time from children. This maps naturally to lazy evaluation — no node materializes its full output unless necessary.

## Plan vs. ExecutorNode: Two-Phase Design

Query execution is split into two distinct phases:

```text
AST (SelectStmt)
  │
  │  plan_select
  │  - resolve table names via catalog
  │  - bind column names to indices
  v
Plan (logical, no data)
  Projection { exprs, columns }
    Filter { predicate }
      SeqScan { table_name, first_page, schema }
  │
  │  Plan::prepare_for_execute
  │  - attach ExecContext for page I/O
  │  - allocate iteration state
  v
ExecutorNode (physical, lazy I/O)
  Projection<C> { child, exprs, columns }
    Filter<C> { child, predicate }
      SeqScan<C> { ctx, buffer, next_page_id }
```

**Plan** is a data-only description of what to do: table names, page IDs, column schemas, bound expressions. It carries no state and no storage references.

**ExecutorNode** is the stateful runtime counterpart. `prepare_for_execute()` converts a Plan into an ExecutorNode tree, passing in an `ExecContext` for storage access. Each node owns its iteration state (scan position, page buffer, etc.).

## Expression Binding: Names to Indices

SQL expressions reference columns by name (`WHERE users.id > 5`), but at execution time, rows are positional arrays. Binding converts name-based `Expr` (AST) into index-based `BoundExpr` (executor) at plan time:

```text
AST:    Expr::ColumnRef { table: "users", column: "id" }
          ↓  .bind(&columns)
Bound:  BoundExpr::Column { index: 0, name: Some("users.id") }
          ↓  .evaluate(&record)
Value:  record.values[0]
```

The `name` field is retained for EXPLAIN display — when printing `$col0 (users.id)`, the human-readable name comes from bind-time resolution, not runtime lookup.

## Expression Evaluation: SQL's Three-Value Logic

The eval module implements the full semantics of SQL expression evaluation, where NULL introduces three-value logic across every operator.

## SeqScan: Balancing Latches and Memory

SeqScan faces a tension: page latches should be held briefly (for concurrency), but tuples must outlive the latch (for lazy iteration). The solution loads all visible tuples from a page into a `Vec<Row>`, releasing the latch before returning any tuple.

Memory usage is bounded by tuples-per-page (not tuples-per-table), since only one page's worth of tuples is buffered at a time.

# Looking Forward

## Deferred: Multi-Page Table Scans

SeqScan currently reads only the first page of a table. Multi-page chaining requires reading a next-page pointer from the page header:

```rust
// Current: stop after first page
self.next_page_id = None;

// Future: follow page chain
self.next_page_id = page.next_page();
```

This will be addressed when tables grow beyond a single 8KB page, likely in conjunction with FSM (Step 15).

## Deferred: Hint Bit Setting

Step 8 noted that visibility checks should set hint bits in tuple headers to cache transaction state. The current SeqScan reads visibility but does not write back hints. This requires acquiring a mutable page latch during scan — a trade-off between read performance and write amplification that will be revisited when VACUUM (Step 15) provides an alternative path for hint bit propagation.

## Production Readiness Gaps

### Per-Row Future Allocation

Each `ExecutorNode::next()` call heap-allocates a `Box<dyn Future>`. For a full table scan returning N rows, this means N allocations. Alternatives:

- Enum-based future dispatch (avoids `dyn`)
- Manual state machines (avoids boxing entirely)
- Batched row processing (amortizes allocation cost)

### Projection Memory Allocation

Projection allocates a new `Vec` and `Record` per row. Arena allocation or a reusable row buffer would reduce allocation pressure for large result sets.

### LIKE Pattern Matching Complexity

The recursive backtracking LIKE implementation has O(n\*m) worst-case complexity for patterns with multiple `%` wildcards. Production systems compile patterns into NFAs for linear-time matching.

### Type Inference for Unrecognized Expressions

The planner defaults to `Text` type for expressions it cannot infer. This may cause type mismatches in Step 11 when INSERT needs accurate types to match target column schemas.
