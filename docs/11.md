# Step 11: DML Operations

> INSERT (set xmin), DELETE (set xmax), UPDATE (delete + insert as new version). Implement type coercion for mixed-type expressions.

# This Step I Learned

## Multi-Page Heap and Page Chain Linkage

Prior to this step, each table occupied a single heap page — enough for catalog bootstrap and basic scans, but DML requires inserting an unbounded number of tuples, so the heap must span multiple pages linked into a chain. When a page fills up, a new page is allocated and appended to the chain; scans walk the chain from the first page to the last.

The page chain requires a `next_page` pointer per page, but this is a heap-specific concern that does not belong in the generic `PageHeader`. The solution is a `HeapFooter` — a 4-byte region at the tail of the page (bytes 8188..8192) that stores `next_page: u32`. By placing it at the tail rather than after `PageHeader`, the slot array still starts immediately after `PageHeader`, and all existing `PageHeader` arithmetic (`free_start`, `free_space`) remains correct without adjustment. The `SlottedPage` struct takes a `footer_size` parameter so it knows where the usable data area ends, making the mechanism extensible for future page types (B+tree will need its own footer with sibling pointers). This approach also preserves `PageHeader`'s 4 reserved bytes for future expansion — these bytes fall within the LSN-protected region of the page, so WAL/recovery can verify header integrity without special-casing the footer.

### Heap Operations as Stateless Free Functions

With multi-page support in place, the next step is to provide composable operations over page chains. `heap::insert`, `heap::delete`, `heap::update`, and `heap::scan_visible_page` are implemented as stateless free functions rather than structs. Each operation is self-contained — there is no cursor position or buffered data to maintain between calls.

`scan_visible_page` returns tuples from a single page plus the next page ID, and the caller (SeqScan or catalog) drives the while-let loop. This keeps the API composable and avoids ownership complications with async iterators that would hold page latches across yield points.

## MVCC Mapping: DML Operations as Tuple Header Manipulations

NOTE: This section is the re-visit of [Step 8: MVCC Core](./8.md).

The core insight of MVCC-based DML is that all three operations reduce to tuple header manipulations:

- **INSERT**: Creates a new tuple with `xmin = current_txid` and `xmax = INVALID`. The tuple is visible only to the inserting transaction (via CommandId) and to other transactions after commit.
- **DELETE**: Sets `xmax = current_txid` and `cmax = current_cid` on the existing tuple. The tuple remains physically present but becomes invisible once the deleting transaction commits.
- **UPDATE**: Performs DELETE on the old version followed by INSERT of the new version, both using the same `txid`/`cid`. Same-page insertion is attempted first to reduce page chain traversal; if the page is full, the function falls back to walking the chain from the first page.

This "delete + insert" model for UPDATE means no in-place record mutation occurs (that path is reserved for MVCC-bypassing operations like sequence `nextval`). The trade-off is that UPDATE always writes a new physical tuple, which increases space consumption until VACUUM reclaims dead versions.

### CommandId Within-Transaction Visibility

CommandId (CID) is critical for intra-transaction visibility of DML results. Each DML statement within a transaction gets a monotonically increasing CID. A tuple inserted at CID N is not visible to the same CID N's snapshot (because the visibility rule requires `cmin < current_cid`), but becomes visible at CID N+1. This ensures that a statement's own modifications don't affect its own scan — matching PostgreSQL's READ COMMITTED behavior where each statement sees a consistent snapshot.

### ExecContext as DML Gateway

The `ExecContext` trait provides `insert_tuple`, `delete_tuple`, `update_tuple`, and `nextval` methods, keeping executor decoupled from concrete storage types. DML nodes call context methods rather than heap functions directly. The context binds the current transaction's `txid` and `cid` (from the snapshot) to each operation, so executors do not need to carry transaction state.

### Volcano Model Adaptation for DML

DML operations do not fit the standard Volcano pull model because they produce a scalar result (affected row count) rather than a stream of rows. The plan type hierarchy is split into `QueryPlan` (row-producing, converted to `QueryNode` via `prepare_for_execute`) and `DmlPlan` (executed via `execute_dml` which returns a `DmlResult`).

DML reuses the Volcano infrastructure internally: UPDATE and DELETE build a `QueryPlan` as their input (SeqScan + optional Filter), convert it to a `QueryNode`, then drive it to completion in a while-let loop, calling `delete_tuple`/`update_tuple` for each row yielded. INSERT is the exception — it evaluates value expressions without a child scan, iterating over the provided rows directly.

`DmlResult` carries operation-specific metadata and formats PostgreSQL-compatible command tags (`INSERT 0 {count}`, `UPDATE {count}`, `DELETE {count}`).

## Type Coercion via BoundExpr

DML planning requires type coercion — an `INSERT INTO t (smallint_col) VALUES (42)` must convert the integer literal (inferred as `Bigint`) to `Smallint`. Rather than building coercion into the planner, the type system is consolidated into `BoundExpr` itself.

`BoundExpr::ty()` returns `Option<Type>`, computing the output type of any expression structurally without consulting external metadata. Literals carry their natural type (`Integer → Bigint`, `Float → Double`), column references carry the type from bind-time resolution, and binary arithmetic uses `Type::to_wide_numeric()` for implicit widening (`Bigint + Double → Double`). NULL returns `None` because it has no inherent type — callers that need a concrete type use `.unwrap_or(Type::Text)`, analogous to PostgreSQL resolving "unknown" to text.

`BoundExpr::coerce(target_type)` wraps a mismatched expression in `BoundExpr::Cast`, deferring actual conversion to evaluation time. NULL and already-matching types pass through unchanged. This lazy approach means the planner only ensures type annotations are in place; conversion errors (e.g., `NumericOutOfRange` when a `Bigint` value overflows `Smallint`) surface at execution time with proper context.

The INSERT planner coerces each value expression to its target column type, and the UPDATE planner coerces each SET expression similarly. This centralization in `BoundExpr` (rather than scattered coercion logic in each planner function) was extracted during the refine phase.

## SERIAL Auto-Population Across Planner and Executor

INSERT must auto-populate SERIAL columns that the user did not explicitly provide. This requires coordination between the planner (which knows the schema) and the executor (which has access to sequence state via `ExecContext`).

The planner identifies SERIAL columns from catalog metadata and filters out those present in the user's explicit column list. The remaining `(column_index, seq_id)` pairs are passed to `DmlPlan::Insert` as `serial_columns`. The planner initializes these positions as `BoundExpr::Null` in the bound row — a placeholder that signals "fill at execution time."

The executor, before inserting each row, calls `ctx.nextval(seq_id)` for each serial column and casts the `i64` result to the column's target type via `Value::cast()`. This split keeps the planner free of sequence state concerns and lets the executor handle transaction-specific sequence semantics (each `nextval` call is non-transactional by design — rolled-back inserts still consume sequence values, matching PostgreSQL behavior).

# Looking Forward

## Write-Write Conflict Detection (Step 20)

The current `delete` function overwrites `xmax` unconditionally. If two concurrent transactions try to delete (or update) the same tuple, the second silently overwrites the first's `xmax`. Row-level locking (Step 20) will add proper write-write conflict detection via a wait-for graph, blocking or aborting the second transaction.

## Non-Atomic Update (Step 13)

The `update` function performs delete then insert as two separate operations. If the insert fails after the delete succeeds (e.g., I/O error), the old version has `xmax` set with no new version. WAL (Step 13) will provide proper rollback guarantees.

## Memory-Proportional Scanning

`scan_visible_page` collects all visible tuples from a page into a `Vec` before releasing the page latch. Memory usage is proportional to visible tuples per page. For production, streaming with explicit latch management would be preferable, especially once Sort/Aggregate (Step 12) may need to scan large tables.

## INSERT ... SELECT

The current INSERT planner binds value expressions with an empty column list, preventing column references in VALUES. Supporting `INSERT ... SELECT` would require a different binding approach where the SELECT subquery's output schema feeds into the INSERT column resolution.

## Free Space Map (Step 15)

The current insert implementation walks the page chain linearly to find free space, which is O(pages) per insert. FSM will provide O(1) page selection for insertions by tracking available space per page.

## Hint Bit Propagation

Visibility checks during scan still do not write back hint bits to tuple headers (deferred from Step 10). VACUUM (Step 15) will provide an alternative path for hint bit propagation.

---

# Side Note

## Fix: COMMIT on Failed Transaction Acts as ROLLBACK

When a statement fails within an explicit transaction, the transaction enters a `failed` state and rejects all subsequent commands with `TransactionAborted` until ROLLBACK. Issuing COMMIT on a failed transaction performs ROLLBACK instead of attempting to commit partial changes — matching PostgreSQL's behavior where a failed transaction block cannot be committed.
